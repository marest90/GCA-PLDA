Configuration parameters:
  [architecture]
    lda_dim = 300
  [training]
    loss = cross_entropy
    ptar = 0.01
    max_norm = 4
    l2_reg = {'default': 0.0001, 'cal_stage.sidep_.*.L': 0.0005, 'cal_stage.sidep_.*.C': 0.0005, 'cal_stage.sidep_.*.G': 0.0005}
    learning_rate = 0.001
    betas = (0.5, 0.99)
    learning_rate_params = None
    init_params = {'w_init': 0.5, 'plda_em_its': 100, 'balance_by_domain': True}
    batch_size = 2048
    num_epochs = 3000
    num_samples_per_class = 2
    num_batches_per_epoch = 1
    compute_ave_model = False
    balance_batches_by_domain = True
Using seed:  0
Loading data from ./data/train/embeddings_dev.h5
  with metadata file ./data/train/metadata_vox_dev
  Done loading embeddings
  Converting metadata strings into indices
Done. Loaded 4903 embeddings from ./data/train/embeddings_dev.h5
Printing graph in output/vox_dev/stage1/models/graph
Initializing trial loader (this might take a while for big datasets but this process saves time during training).
  Creating dictionary with a list of class_id for each ['domain_id']
  Creating dictionary with a list of session_id for each ['class_id', 'domain_id']
  Creating dictionary with a list of sample_id for each ['session_id', 'class_id', 'domain_id']
  Creating dictionary with a list of domain_id for each ['class_id']
Selecting 5 classes for domain VOX, and 2 samples per selected class
Done Initializing trial loader
Will create 1 batches of size 10 per epoch using 4903 samples
Torchviz unavailable. Skipping graph creation
List of model parameters:
   lda_stage.W torch.Size([512, 300])
   lda_stage.b torch.Size([300])
   plda_stage.L torch.Size([300, 300])
   plda_stage.G torch.Size([300, 300])
   plda_stage.C torch.Size([300, 1])
   plda_stage.k torch.Size([])
   cal_stage.alpha torch.Size([])
   cal_stage.beta torch.Size([])

####################################################################################
Starting training
Loading data from ../../DCA-PLDA/examples/speaker_verification/data/eval/voxceleb2_4-16sec/embeddings_test.h5
  with metadata file ../../DCA-PLDA/examples/speaker_verification/data/eval/voxceleb2_4-16sec/durations
  Done loading embeddings
  Converting metadata strings into indices
Done. Loaded 4903 embeddings from ../../DCA-PLDA/examples/speaker_verification/data/eval/voxceleb2_4-16sec/embeddings_test.h5
Loaded 4903 1-session models from ../../DCA-PLDA/examples/speaker_verification/data/eval/voxceleb2_4-16sec/enroll.lst
Loaded 4903 1-session models from ../../DCA-PLDA/examples/speaker_verification/data/eval/voxceleb2_4-16sec/test.lst
Loaded key file ../../DCA-PLDA/examples/speaker_verification/data/eval/voxceleb2_4-16sec/keys/all.h5
Some of the files (29) in the subset are missing. Ignoring them
Initializing trial loader (this might take a while for big datasets but this process saves time during training).
  Creating dictionary with a list of class_id for each ['domain_id']
  Creating dictionary with a list of session_id for each ['class_id', 'domain_id']
  Creating dictionary with a list of sample_id for each ['session_id', 'class_id', 'domain_id']
  Creating dictionary with a list of domain_id for each ['class_id']
Selecting 1024 classes for domain VOX, and 2 samples per selected class
Done Initializing trial loader
Will create 1 batches of size 2048 per epoch using 4903 samples
hola, llegue
<dca_plda.data.TrialLoader object at 0x7f0428bdbc70>
0
(tensor([[-16.2505, -12.0114,  12.1643,  ...,   3.6646, -19.0497, -11.1183],
        [-14.8112, -15.8656,  14.0224,  ...,   3.5973, -25.5879, -11.6376],
        [-12.8514, -15.1678,  16.4964,  ...,   3.5825, -18.7193, -11.5370],
        ...,
        [-15.7257, -17.5942,  10.6002,  ...,   3.0194, -24.8955, -15.7317],
        [-16.8616, -17.9457,  11.2810,  ...,   3.0273, -24.4676, -12.9436],
        [-16.3444, -17.1181,  11.6796,  ...,   2.9650, -21.7033, -13.6605]]), {'sample_id': tensor([3588., 3578., 3563.,  ..., 3324., 2507., 2493.]), 'class_id': tensor([86., 86., 85.,  ..., 77., 61., 61.]), 'session_id': tensor([3588., 3578., 3563.,  ..., 3324., 2507., 2493.]), 'domain_id': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'duration': tensor([5.2100, 6.0200, 3.3100,  ..., 6.2300, 8.6800, 3.5600])})
tensor([-16.2505, -12.0114,  12.1643, -35.0582,   3.5642, -20.9590,  10.6016,
        -16.4630,   2.5125,  -1.2658,   0.5761,  -2.3635,   3.4974,  -4.6114,
         -1.5559, -34.6500, -20.6677,  10.6224, -11.9598, -14.1439,  21.0496,
         20.2092,  10.1555,   5.0781, -13.4746,   1.3952,  12.8235,  12.8062,
         11.5741, -15.9660,  18.6070, -23.3513, -29.5744,  11.5824, -19.2982,
         -4.1998,  14.3638,   2.2570, -13.9997,   6.5457,  11.9752,  13.9787,
         17.7271,  -2.6886,  15.1260, -23.7316, -18.7763,  -0.1233, -20.1410,
        -17.2347, -15.7230, -15.4659,  21.3958, -20.4698, -29.0568,  -8.4691,
          4.5564,   2.8549,  14.8393, -27.0015, -20.1233, -17.7822, -21.8540,
          5.9330,  16.2065,  -3.4125,   1.5401,  11.0037,  21.6889, -14.8332,
        -14.3369, -14.8266,   4.0115, -22.3737, -20.2975, -21.4609,   5.3282,
        -19.4499,   4.2072,  -3.2087,   2.3744,  14.6832,  11.4276,  11.6729,
          0.2345,  10.6180,  -1.5505, -23.3016, -17.6656,  10.9726,  -6.7072,
         16.1649, -20.1246, -30.0078,   3.3716,  17.1744,   7.4283, -18.1969,
        -27.2444,  -1.3370,   7.4363,  19.0365, -18.4780, -21.6766,  25.9267,
         18.7629, -23.9292,  22.9683,   8.3873,  20.8510, -24.6455,   7.4938,
         10.5467, -29.4466, -25.8492,   4.6661,  -5.6504,   8.0117,  11.7217,
         17.8484,  -3.1495, -22.4877,   6.5684,  -6.6464,   3.4782, -23.7557,
        -25.6004, -16.4310,  12.4289,  -2.0891, -22.5020,  20.9846,  15.4869,
          8.8529, -18.9642,  -7.7083,  -7.9614,   4.2036,  -9.6085,  20.3020,
         16.0440,  10.3486, -35.0904,  27.6465,  -8.3493,  10.2261,  18.6715,
          5.7046,  -4.7623,   8.2595,  -0.0503,   8.5079,   7.8220,  26.2377,
         -3.9288, -16.7075,   2.3865, -22.5326, -21.6951,  12.7156,  17.3391,
        -28.4728,  -7.4562, -22.1736,  -1.3364, -27.3227, -15.8518,  13.7943,
         -3.4229,  11.6194,  12.1626, -23.7976,  -0.9605,  12.3374, -24.6491,
        -22.7161,  -3.3299,   4.4585, -33.4574,   4.4363,  11.9705, -30.9835,
         -6.9517,   3.8511,  -4.1358, -22.6532,   4.1697,   1.4544,  -2.8885,
        -23.3512,   5.2020,  -2.1755, -17.4997, -14.2443,  13.9382,  -3.9860,
         -3.8852,  -7.2277, -16.6685,  19.9654,  -0.1678, -17.1979, -25.2050,
         23.7197, -18.3872,   0.1453, -28.7074,  11.6476,   5.9489, -20.7782,
         -0.6373, -13.9254,  16.9854,  16.2198, -27.6766,   9.1985, -16.1350,
         19.1268,  -9.0410,  14.8842,   9.1518,   5.6439,   8.6385,  13.6362,
          2.7472,   9.7147,  20.0640, -28.2867,  -0.1955,  11.9745, -19.3859,
        -14.6070,  -6.2032, -23.3206,  19.8212,   3.2538,  -8.2236, -23.2679,
        -35.7012,  -0.1079,  25.6823,   4.1327, -12.2440,  11.5289, -30.1307,
        -28.1781, -17.5111,   7.6046,   2.5281, -26.5164, -21.0475,   2.4918,
          2.1391, -18.9617,  12.1082,   6.9147,   4.6077,  10.8291,  17.1369,
         -3.0970,  -3.7616, -17.6246, -28.3073,  12.3812,  17.9407,   4.7474,
        -18.2469,   1.9752,   3.0953,  -9.5970, -23.2346,  20.3673,  14.4763,
          2.9592,   3.5964, -11.7276, -20.3423,  17.9229, -21.2075,   3.2922,
         26.9957,   9.4410,   4.6934,  11.9971,   2.9843,  -0.3935, -25.4926,
         10.8712,  -1.1842,  25.1381, -23.9502,  11.4028, -29.4840,   7.2660,
        -13.6966,  -0.6758, -13.3209, -15.5195, -32.8555,  14.7514,  -2.0126,
         -2.4808,  -8.2171,   1.3273,  13.6568,   4.5841,   7.2645, -11.1446,
        -17.0948,  -3.8258,   5.0632,  17.4401,   1.4705,  16.2195, -28.2062,
         -4.7263, -21.1727,  11.9494,   8.0834,  15.7390, -15.8393,   2.4624,
         14.2676,   7.5773,  -4.3779,  12.9306, -22.4369, -16.1054,  18.3037,
          4.3348, -32.0396,  -1.3843,   5.1814, -24.0392,   1.2570, -22.2053,
         -4.8465, -19.5139,   4.6203,   9.2061,  -0.9526,  13.1518,   4.0071,
         12.9178,  12.8317,   8.1291,   6.1562,  13.1909,   9.8786,   4.1557,
          3.8669,   3.0678,   1.1436,   5.6961, -23.5167, -20.8002,  10.0306,
          4.2012,  21.0714, -24.6261,   8.4313,  -1.8323, -20.5094, -19.7392,
          3.7015,   8.1376,  11.3319,  -4.8070, -22.2267, -10.8449,  19.6941,
          5.6197,   2.0347,   4.6808,   9.9729, -17.5610,  16.0495,   3.2296,
         17.0153,   0.3272,   3.8912,   3.6029,   1.3096, -12.0976,   4.9257,
        -28.9203, -29.8728,  -4.6300,   8.4520, -19.3519,  17.9580,   6.0119,
         14.8996,   9.3425, -22.6130, -13.0803,  10.5430, -20.2626,   5.4475,
        -27.7975,  14.5881,  18.2988,   8.2646, -25.6360,   8.5472,  -5.0252,
         13.2503,   5.8022,   8.8303,   3.9866,  -0.2131,  13.8753,   3.9773,
        -31.9679,  10.4922, -20.3613, -22.3706,   1.6006,  -2.0972, -23.5686,
        -23.5745, -29.1110,   7.6503, -10.3501, -23.5406,  12.5807, -26.3998,
         12.3412, -20.7627,  18.8686,  -0.2457,  14.4312, -19.2016, -12.3502,
         22.0506,   6.6310,  11.8502, -27.7484,   3.2416,   2.4116, -16.7363,
         19.9053,  -8.9767,  24.8606, -12.0440,   7.1097,   2.9556, -21.0910,
        -30.3620,  12.6758,   9.3987, -28.4381, -17.1701,   4.0162, -29.0731,
         22.6569,  -8.3589,   4.1406, -26.2310,  -5.5241,  10.2093,  -9.8950,
          3.5985,  -8.6572, -15.9187,  14.9544,  -7.1429,   2.4775,   5.2935,
         18.1705,   8.5996,  10.8242,   9.1868, -31.5563,  19.4137,  -0.7767,
        -12.7058,  11.9268, -25.0047, -24.0667,  18.4985,   6.3966,   0.4216,
        -16.7282,   4.5104,  12.4735,   3.2536,  13.0480, -19.7008,   3.7295,
        -23.4086, -25.8157,   4.3571,  -5.5266,   2.0378,  -1.5807,   6.6866,
          2.2160,  14.4960,  13.1114, -22.0649,   1.6168,   3.8728,  10.4850,
        -22.1688, -19.4870,   4.0748,   3.6377,  -8.0334,   3.6646, -19.0497,
        -11.1183])
